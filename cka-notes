Note : 
Set auto-completion for aliases
complete -p YOUR_CMD # find the command fucntion
complete -F YOUR_CMD_FUNCTION kubectl # set this in bashrc

WARNING : FAIRE UN FOCUS SUR 
- LES API-GATEWAY
- LES STRATEGY DANS LES DEPLOYMENT
- KUSTOMIZE
- HELM
- YQ

## RBAC :
Subject: The user or process that wants to access a resource.
Resource: The Kubernetes API resource type e.g. a Deployment or node.
Verb: The operation that can be ex
kubectl create role <name> --verb=<verbs> --resource=<resources> -n <ns>
kubectl create rolebinding <name> --role=<role> --user=<user> -n <ns>
kubectl create clusterrole ...
kubectl create clusterrolebinding ...
kubectl auth can-i <verb> <resource> --as <user>


# create a user in k8s : https://kubernetes.io/docs/tasks/tls/certificate-issue-client-csr
# change the default ns
kubectl config set-context --current --namespace=NAMESPACE

# YAML syntax
microservice : #objet
  app : auth # key : value
  port : 300
  version : 1.7

# In case of list :

microservice :
  - app : auth
    port : 300
    version : 1.7
  - app: user
    port : 3009
    version : 1.8

# paste un multiline dans un yaml file
mylines: |
   line 1
   line 2
   line 3

Exemple executer un script 
command: 
   - sh
   - -C 
   - |
    Paste all 
    Your script 

#Paste a long sentence in  yaml
mylongsentence: >
    Mariame joue
    a la balle 
    avec bile 
    son ami

# check permission
kubectl auth can-i --list --as johndoe
kubectl auth can-i list pods --as johndoe

# Update iptables config
cat <<EOF > /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
EOF
sudo sysctl --system

# Backup and restore ETCD
### Backup
ETCDCTL_API=3 etcdctl --endpoints=https://127.0.0.1:2379 \
  --cacert=<trusted-ca-file> --cert=<cert-file> --key=<key-file> \
  snapshot save <backup-file-location>

Exemple : 
ETCDCTL_API=3 etcdctl --endpoints=https://127.0.0.1:2379 \
  --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/server.crt --key=/etc/kubernetes/pki/etcd/server.key \
  snapshot save /tmp/snapshot.db

#### Restore
export ETCDCTL_API=3
etcdctl --data-dir <data-dir-location> snapshot restore snapshot.db

Now edit /etc/kubernetes/manifests/etcd.yaml and change **volumes.hostPath.path** for name: etcd-data to <data-dir-location>,
then execute kubectl -n kube-system delete pod <name-of-etcd-pod> or systemctl restart kubelet.service or both

# Determine the api-server endpoint
kubectl config view --minify -o jsonpath='{.clusters[0].cluster.server}'

# Get the Secret access token of a ServiceAccount
kubectl get secret $(kubectl get serviceaccount api-access -n apps \
 -o jsonpath='{.secrets[0].name}') -o jsonpath='{.data.token}' -n apps \
 | base64 --decode

# Curl for listing pods in ns rm from a pod
curl https://10.10.10.38:6443/api/v1/namespaces/rm/pods --header --insecure

#  Rolling Updates and Rollbacks 
### Rolling update
 kubectl set image deployment app-cache memcached=memcached:1.6.10 --record

### Check a rollout status
k rollout status deployment app-cache

### Check rollout history
k rollout history deployment app-cache

### Get more details about a rollout
k rollout history deployment app-cache --revision=2

### Rolling back
kubectl rollout undo deployment app-cache --to-revision=1

# Scaling Workloads
## Manually
kubectl scale deployment app-cache --replicas=6
kubectl scale statefullset redis --replicas=4

## HPA (Horizontal Pod AutoSacaler)
kubectl autoscale deployment app-cache --cpu-percent=80 --min=3 --max=5

Warning :
The HorizontalPodAutoscaler is an API kind in the Kubernetes autoscaling API group. 
The current stable version can be found in the autoscaling/v2 API version which includes support for scaling on memory and custom metrics.

apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  creationTimestamp: null
  name: app-cache
spec:
  maxReplicas: 3
  minReplicas: 1
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: app-cache
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 60
  - type: Resource
    resource:
      name: memory
      target:
        type: AverageValue
        averageValue: 500Mi

For the metrics to appear when running kubectl get hpa, metric server should be installed and rsource request/limits should be configured.

# SECRET AND CONFIGMAP

#### CONFIGMAP
Source options for data parsed by a ConfigMap :

--from-literal : --from-literal=locale=en_US Literal values, which are key-value pairs as plain text
kubectl create configmap db-config --from-literal=DB_HOST=mysql-service --from-literal=DB_USER=backend
```
apiVersion: v1
data:
  DB_HOST: mysql-service
  DB_USER: backend
kind: ConfigMap
metadata:
  name: db-config
---
apiVersion: v1
kind: Pod
metadata:
  name: backend
spec:
  containers:
  - image: mysql:9
    name: backend
    envFrom:
    - configMapRef:
        name: db-config
```
--from-file : --from-file=app-config.json A file with arbitrary contents
kubectl create configmap db-config --from-file=db.json
```
apiVersion: v1
data:
  db-config.json: |
    {
     "db": {
     "host": "mysql-service",
     "user": "backend"
     }
    }
kind: ConfigMap
metadata:
  creationTimestamp: null
  name: db-config2
---
apiVersion: v1
kind: Pod
metadata:
  name: db
spec:
  containers:
  - image: bmuschko/web-app:1.0.1
    name: db
    volumeMounts:
      - name: db-volume
        mountPath: /etc/config
  volumes:
    - name: db-volume
      configMap:
        name: db-config2
```

--from-env-file : --from-env-file=config.env A file that contains key-value pairs and expects them to be environment variables
--from-file :  --from-file=config-dir A directory with one or many files

##### SECRET
--fromliteral : --from-literal=password=secret Literal values, which are key-value pairs as plain text

```
apiVersion: v1
kind: Pod
metadata:
  name: backend
spec:
  containers:
  - image: mysql:9
    name: backend
    envFrom:
    - configMapRef:
        name: db-config
```

--from-envfile : --from-env-file=config.env A file that contains key-value pairs and expects them to be environment variables
--from-file : --from-file=id_rsa=~/.ssh/id_rsa A file with arbitrary contents
--from-file : --from-file=config-dir A directory with one or many files

# Kustomize
Kustomize needs the kustomization.yaml and this file defines the processing rules Kustomize works upon.
kubectl kustomize <target> : similar to dry-run
kubectl apply -k <target> : To apply

```
configMapGenerator:
- name: db-config
  files:
   - config/db-config.properties
secretGenerator:
- name: db-creds
  files:
   - config/db-secret.properties
resources:
- web-app-pod.yaml
```
---

```
namespace: persistence
commonLabels:
 team: helix
resources:
- web-app-deployment.yaml
- web-app-service.yaml
```
---

##### defines a security context on the container-level for the Pod template of the Deployment. The security rule should be define in a file like security-context.yaml

```
resources:
- nginx-deployment.yaml
patchesStrategicMerge:
- security-context.yaml
```

# YAML Processor yq
#### Reading values : yq -e
yq e .metadata.name pod.yaml

### Modifying values
yq e -i '.spec.containers[].env[1].value = "1.7.0"' spring-boot-app.yaml

# Helm
Chart.yaml describes the meta information of the chart (e.g., name and version)
values.yaml contains the key-value pairs used at runtime to replace the placeholders in the YAML manifests. 
helm template . : for templating, like dry-run
helm package : for tar the templating output

# Know the subnet assigned to the nodes by the CNI
kubectl get nodes k8s-worker-1 -o json | jq .spec.podCIDR

# Use busybox for testing
kubectl run busybox --image=busybox --rm -it --restart=Never -- wget 192.168.230.37:80

# Create service
k create service clusterip echoserver --tcp=80:8080 # create service that expose en existing pod pod echoserver
kubectl run echoserver1 --image=k8s.gcr.io/echoserver1:1.10 --restart=Never --port=8080 --expose # run a pod and expose it (service directly)
kubectl expose deployment echoserver --port=80 --target-port=8080 # expose a deployment

# create ingress
kubectl create ingress corellian  --rule="star-alliance.com/corellian/api=corellian:8080" # Where rule="<host>/<path>=<service>:<port>"
kubectl get ingress corellian --output=jsonpath="{.status.loadBalancer.ingress[0].ip}" # jsonpath to get the IP of an ingress IP

# Coredns
kubectl run busybox --image=busybox --rm -it --restart=Never -n dns -- wget echoserver:8080 # Make a call from a pod to a svc in the same ns using the hostname
k run busybox --image=busybox --rm -it --restart=Never -n business -- wget echoserver.other:8080 # From different ns
kubectl run busybox --image=busybox --rm -it --restart=Never -n business  -- wget echoserver.other.svc:8080
kubectl run busybox --image=busybox --rm -it --restart=Never -n business  -- wget echoserver.other.svc.cluster.local:8080
kubectl run busybox --image=busybox --rm -it --restart=Never -n ns1 -- wget 192-168-140-13.ns1.pod:8080 # make a call to a pod via the ip in the same ns. Where 192-168-140-13.ns1.pod:8080 is ip.ns.pod:port

#jsonPath
k get pod echoserver1 -n ns1 --template={{.status.podIP}} # get the IP of pod echoserver1 running in ns ns1


# Tshoot
## 503 Service Unavailable, service has no endpoint
Symptom: curl nginx.home.lan/echo returned 503 Service Temporarily Unavailable.
Cause: The Kubernetes Service echoserver had no active Endpoints (ENDPOINTS <none>). This was caused by a Label Selector Mismatch.
Service Selector: app=echoserver
Pod Label: run=echoserver
Because the labels didn't match, the Service didn't know which Pods to send traffic to.
The Fix: We edited the Service (kubectl edit svc) to match the Pod's label (run=echoserver).
Key Takeaway: A 503 from an Ingress usually means the Ingress Controller cannot connect to the backend Service. Always check kubectl get endpoints to verify the Service has found its Pods.


# Volume
## volume Types
emptyDir : Empty directory in Pod with read/write access. Persisted for only the lifespan of a Pod. A good choice for cache implementations or data exchange between containers of a Pod.
hostPath : File or directory from the host node’s filesystem.
configMap, secret: Provides a way to inject configuration data. For practical examples, see “Defining and Consuming Configuration Data”.
nfs : An existing Network File System (NFS) share. Preserves data after Pod restart.
persistent VolumeClaim : Claims a persistent volume.

### PVC/PV

┌──────────┐
│   Pod    │
│          │
│ utilise  │
│ un       │
│ volume   │
└────┬─────┘
     │
     ▼
┌───────────────┐
│      PVC      │
│ Persistent    │
│ Volume Claim  │
│               │
│ "J’ai besoin  │
│ de 10Gi,      │
│ RWX, etc."    │
└────┬──────────┘
     │
     ▼
┌───────────────┐
│      PV       │
│ Persistent    │
│ Volume        │
│               │
│ Stockage réel │
│ (NFS, disque, │
│ cloud, etc.)  │
└───────────────┘
